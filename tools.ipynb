{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3dc240",
   "metadata": {},
   "source": [
    "# Llama 3.1 Tool Use Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b9dbc",
   "metadata": {},
   "source": [
    "This notebook explores the agentic capabilities in the Llama 3.1 instruction models. Our goal is to show how the tool system works under the hood, so you have a clear understanding of its capabilities. For deployment options, you may want to consider the [`llama-agentic-system`](https://github.com/meta-llama/llama-agentic-system) or [`llama-stack`](https://github.com/meta-llama/llama-stack) repos, which provide higher-level wrappers and convenience tools to build complete solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b56d17",
   "metadata": {},
   "source": [
    "We'll get started just with the bare [`meta-llama/Meta-Llama-3.1-8B-Instruct`](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct) model, and will show how to complete tool invocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828f39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7acbe545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89201ef7a95a432db297f5d5928cf7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c1959",
   "metadata": {},
   "source": [
    "## Built-in Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1cf8d",
   "metadata": {},
   "source": [
    "The Llama 3.1 models were trained with knowledge about a few built-in tools, which include `brave_search` for Web browsing and `wolfram_alpha` for mathematical and computational queries. This means that the model already knows when it's a good time to use these tools, and how to interpret the results from the corresponding services.\n",
    "\n",
    "You must opt-in to use these services, otherwise the model will act as if it knew nothing about the tools. The way to enable them is using a special version of the system prompt that must include the first two lines shown below: `Environment: ipython`, followed by the list of tools the model can use. The remaining part of the system prompt can be configured at will.\n",
    "\n",
    "We use the chat template built into the tokenizer to convert our conversation (the system prompt plus a query) into a text input for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6031d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\\\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "\n",
    "You are a helpful assistant\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"Who are the contenders for the next USA presidential election in November?\"},\n",
    "]\n",
    "\n",
    "tokenized = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5996bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Environment: ipython\n",
      "Tools: brave_search, wolfram_alpha\n",
      "\n",
      "You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who are the contenders for the next USA presidential election in November?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ae0bd",
   "metadata": {},
   "source": [
    "Note that default dates are automatically added by the template as well.\n",
    "\n",
    "Tokenization follows the particularities of the Llama 3.1 conversation template, with the delimiters and separators that were used during training. This is essential to preserve the quality of responses. Once we have verified that the input looks fine, we can actually run the tokenization to pass the numerical input ids to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edf2c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5727ba60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|python_tag|>brave_search.call(query=\"USA presidential election contenders 2024\")<|eom_id|>\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "assistant_response = tokenizer.decode(response, skip_special_tokens=False)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d0df8",
   "metadata": {},
   "source": [
    "Based on our input, the model correctly recognized the need to search the web for an answer. The `<|python_tag|>` token is just the one they chose to indicate that a tool call invocation is needed – it does not really imply that it has to be done in Python. We are free to use whatever mechanism we want to invoke the tool – all that matters is that it processes the `query` and returns the answers in the format expected by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498eabca",
   "metadata": {},
   "source": [
    "To complete the query, we are going to use Meta's reference implementation of the tool, which we took from [the llama-stack repo](https://github.com/meta-llama/llama-stack/blob/f2e18826b6f9c0122eb714f3bda404da19d2355b/llama_toolchain/agentic_system/meta_reference/tools/builtin.py#L88). We do it this way because:\n",
    "- It's already implemented.\n",
    "- We must ensure the output format is exactly the one expected by the model. Using the reference implementation guarantees that's the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67523b0a",
   "metadata": {},
   "source": [
    "Before we proceed, note that this is **not** the final response from the model yet. Tool calling happens without the user intervening, as an intermediate step our application has to handle. If this code was part of a chat service, we'd display a progress indicator and probably a message that we are browsing the web to retrieve additional information. The user is never shown the `brave_search.call` response. What follows is what our code has to do to complete the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d945e3",
   "metadata": {},
   "source": [
    "Since we are relying on the official implementation by Meta, we import the tool reference code from `llama_stack`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2efa0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_toolchain.agentic_system.meta_reference.tools.builtin import BraveSearchTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b563a3",
   "metadata": {},
   "source": [
    "The Brave search tool requires an API key to work. You can sign up for a free subscription (it's free, but a credit card is required) [here](https://api.search.brave.com/register). It has a rate limit of 1 query per second, which is enough for development.\n",
    "\n",
    "Please, _never_ write any token in source code, it's very insecure. I put my key in an environemnt variable because I'm writing this notebook locally. If you run it in Google Colab, you can also add your key as a secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a0e0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "brave = BraveSearchTool(os.environ[\"BRAVE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2575b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brave_search'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brave.get_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5435d1",
   "metadata": {},
   "source": [
    "The API to run the tool is [here](https://github.com/meta-llama/llama-stack/blob/f2e18826b6f9c0122eb714f3bda404da19d2355b/llama_toolchain/agentic_system/meta_reference/tools/builtin.py#L42), but it relies on higher-level message types that we are not using. Instead, we'll just invoke the backend implementation like follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1c25837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"query\": \"USA presidential election contenders 2024\", \"top_k\": [{\"title\": \"2024 United States presidential election - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/2024_United_States_presidential_election\", \"description\": \"Jason Palmer, who surprised many ... president since Ted Kennedy in 1980. However, he suspended his campaign on May 15, <strong>2024</strong>. On March 12, <strong>2024</strong>, Biden secured a majority of delegates, becoming the presumptive Democratic nominee. Despite securing the nomination, Biden faced significant opposition ...\", \"type\": \"search_result\"}, {\"title\": \"Who Is Favored To Win The 2024 Presidential Election? | FiveThirtyEight\", \"url\": \"https://projects.fivethirtyeight.com/2024-election-forecast/\", \"description\": \"538\\\\u2019s <strong>2024</strong> <strong>presidential</strong> <strong>election</strong> forecast model showing Democrat Kamala Harris\\\\u2019s and Republican Donald Trump\\\\u2019s chances of winning.\", \"type\": \"search_result\"}, {\"title\": \"Presidential candidates, 2024 - Ballotpedia\", \"url\": \"https://ballotpedia.org/Presidential_candidates,_2024\", \"description\": \"Harris won a majority of delegates ... July 15, <strong>2024</strong>.[1][2][3] In addition to noteworthy candidates, this page also provides the names of all candidates who have filed with the Federal <strong>Election</strong> Commission and the names of politicians and public figures discussed as potential <strong>presidential</strong> <strong>contenders</strong> ...\", \"type\": \"search_result\"}]}'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = await brave.run_impl(\"USA presidential election contenders 2024\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea2fcc",
   "metadata": {},
   "source": [
    "The response from the tool is a string that must be appended to the model assistant turn, like follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "524dc69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|python_tag|>brave_search.call(query=\"USA presidential election contenders 2024\")<|eom_id|>\n",
      "\n",
      "{\"query\": \"USA presidential election contenders 2024\", \"top_k\": [{\"title\": \"2024 United States presidential election - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/2024_United_States_presidential_election\", \"description\": \"Jason Palmer, who surprised many ... president since Ted Kennedy in 1980. However, he suspended his campaign on May 15, <strong>2024</strong>. On March 12, <strong>2024</strong>, Biden secured a majority of delegates, becoming the presumptive Democratic nominee. Despite securing the nomination, Biden faced significant opposition ...\", \"type\": \"search_result\"}, {\"title\": \"Who Is Favored To Win The 2024 Presidential Election? | FiveThirtyEight\", \"url\": \"https://projects.fivethirtyeight.com/2024-election-forecast/\", \"description\": \"538\\u2019s <strong>2024</strong> <strong>presidential</strong> <strong>election</strong> forecast model showing Democrat Kamala Harris\\u2019s and Republican Donald Trump\\u2019s chances of winning.\", \"type\": \"search_result\"}, {\"title\": \"Presidential candidates, 2024 - Ballotpedia\", \"url\": \"https://ballotpedia.org/Presidential_candidates,_2024\", \"description\": \"Harris won a majority of delegates ... July 15, <strong>2024</strong>.[1][2][3] In addition to noteworthy candidates, this page also provides the names of all candidates who have filed with the Federal <strong>Election</strong> Commission and the names of politicians and public figures discussed as potential <strong>presidential</strong> <strong>contenders</strong> ...\", \"type\": \"search_result\"}]}\n"
     ]
    }
   ],
   "source": [
    "assistant_turn = assistant_response + \"\\n\\n\" + results\n",
    "print(assistant_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3f9eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\", \"content\": assistant_turn\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55425c1b",
   "metadata": {},
   "source": [
    "So our full conversation now consists of three messages: the system prompt, the user query, and the results from the tool. We send all this back to the model, while our progress indicator would still be running on the user's UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f9636c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Environment: ipython\\nTools: brave_search, wolfram_alpha\\n\\nYou are a helpful assistant'},\n",
       " {'role': 'user',\n",
       "  'content': 'Who are the contenders for the next USA presidential election in November?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<|python_tag|>brave_search.call(query=\"USA presidential election contenders 2024\")<|eom_id|>\\n\\n{\"query\": \"USA presidential election contenders 2024\", \"top_k\": [{\"title\": \"2024 United States presidential election - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/2024_United_States_presidential_election\", \"description\": \"Jason Palmer, who surprised many ... president since Ted Kennedy in 1980. However, he suspended his campaign on May 15, <strong>2024</strong>. On March 12, <strong>2024</strong>, Biden secured a majority of delegates, becoming the presumptive Democratic nominee. Despite securing the nomination, Biden faced significant opposition ...\", \"type\": \"search_result\"}, {\"title\": \"Who Is Favored To Win The 2024 Presidential Election? | FiveThirtyEight\", \"url\": \"https://projects.fivethirtyeight.com/2024-election-forecast/\", \"description\": \"538\\\\u2019s <strong>2024</strong> <strong>presidential</strong> <strong>election</strong> forecast model showing Democrat Kamala Harris\\\\u2019s and Republican Donald Trump\\\\u2019s chances of winning.\", \"type\": \"search_result\"}, {\"title\": \"Presidential candidates, 2024 - Ballotpedia\", \"url\": \"https://ballotpedia.org/Presidential_candidates,_2024\", \"description\": \"Harris won a majority of delegates ... July 15, <strong>2024</strong>.[1][2][3] In addition to noteworthy candidates, this page also provides the names of all candidates who have filed with the Federal <strong>Election</strong> Commission and the names of politicians and public figures discussed as potential <strong>presidential</strong> <strong>contenders</strong> ...\", \"type\": \"search_result\"}]}'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423ad7b",
   "metadata": {},
   "source": [
    "We tokenize and use the model to generate additional text. Note that, in this case, we are setting `add_generation_prompt` to `False`. If we used `True`, the tokenizer would append the tokens that invite the model to start an assistant response. But we are still in the middle of an assistant response that is in the process of being finalized, so we don't need those tokens now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8c7dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=False,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4d36c6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The contenders for the next USA presidential election in November 2024 are:\n",
      "\n",
      "* Kamala Harris (Democrat)\n",
      "* Donald Trump (Republican)\n",
      "* Jason Palmer (who suspended his campaign on May 15, 2024)\n",
      "* Joe Biden (presumptive Democratic nominee)\n",
      "\n",
      "Note: The list of contenders may not be exhaustive, as the search results only provide information on the most notable candidates.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "assistant_response = tokenizer.decode(response, skip_special_tokens=False)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dac3be",
   "metadata": {},
   "source": [
    "If you skim over the search results returned by the tool, it's understandable that the model gave this response! Also, if the search query results are different when you run this notebook, you may get different results.\n",
    "\n",
    "In any case, this is the **final response for this assistant turn**, to be presented to the user. If we want to continue the conversation, we need to replace the last assistant turn with this message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5ccee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Environment: ipython\\nTools: brave_search, wolfram_alpha\\n\\nYou are a helpful assistant'},\n",
       " {'role': 'user',\n",
       "  'content': 'Who are the contenders for the next USA presidential election in November?'},\n",
       " '<|start_header_id|>assistant<|end_header_id|>\\n\\nThe contenders for the next USA presidential election in November 2024 are:\\n\\n* Kamala Harris (Democrat)\\n* Donald Trump (Republican)\\n* Jason Palmer (who suspended his campaign on May 15, 2024)\\n* Joe Biden (presumptive Democratic nominee)\\n\\nNote: The list of contenders may not be exhaustive, as the search results only provide information on the most notable candidates.<|eot_id|>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[-1] = assistant_response\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb1e3d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee3208",
   "metadata": {},
   "source": [
    "## Creating a Custom Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247de88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd505c3",
   "metadata": {},
   "source": [
    "## Unified Tool Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d78d1",
   "metadata": {},
   "source": [
    "From https://huggingface.co/blog/unified-tool-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05e58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47f933db",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e41dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
